{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9dL6NwLOGkv7FIIBeHDkc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbberylll/ESAA_OB/blob/main/Untitled22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[## IEEE-CIS Fraud Detection / Credit Card Fraud Detection](https://www.kaggle.com/competitions/credit-card-fraud-prediction/data?utm_source=chatgpt.com)\n",
        "\n",
        "1. Credit Card Fraud Detection 대회 (거래 기반)\n",
        "주어진 거래 기록(transaction) + 일부 신원(identity) 변수로 fraud 여부(isFraud) 예측하는 이진 분류 문제\n",
        "\n",
        "2. 거래 데이터에는 TransactionDT (시간 경과 값), card 관련 변수, 여러 Vxxx 변수 등 시계열/시간 정보와 직접적으로 연결된 피처들이 포함됨.\n",
        "\n",
        "3. 레이블이 매우 불균형 (fraud 비율이 매우 낮음)\n",
        "\n",
        "4. 평가 지표는 AUC 등 분류 성능 중심\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "### 상위권 솔루션 핵심 전략 & 특징\n",
        "1. 시간 차이 피처 활용\n",
        "  * D1 ~ D15 등, 이전 거래까지의 시간 차이 변수들이 주어져 있음\n",
        "  * 이 변수들이 “최근 거래 빈도성/시간 간격 패턴”을 대표할 수 있음\n",
        "2. TransactionDT 파생 변수\n",
        "  * day = TransactionDT / (24* 60 * 60)처럼 시간 단위로 변환 → 일(day) 단위 피처 생성\n",
        "  * 거래 간 시간 간격, 일(day-of-week), 시간대 효과 반영\n",
        "3. UID / 그룹별 집계 피처\n",
        "  * 상위 솔루션에서는 card + addr 등을 조합해 UID (고객 또는 단위 그룹 아이디) 생성 → 그룹별 집계 통계 (mean, std 등) 등록\n",
        "  * UID별 거래 패턴 변화: 예를 들어 고객별 하루 거래 수 변화, 하루 전 대비 변화율 등\n",
        "4. Aggregation / Rolling / Lag 피처\n",
        "  * 예: 특정 기간 내 거래 수, 거래 금액 평균/표준편차, 최근 N개 거래 기준 통계 등\n",
        "  * 시계열 예측처럼 “과거 N 거래 패턴이 미래 사기 확률에 미치는 영향”을 반영\n",
        "5. 모델 앙상블 + 스태킹\n",
        "  * XGBoost + LightGBM + CatBoost 조합\n",
        "  * 서로 다른 모델이 시간 기반 패턴을 포착하는 방식이 다르기 때문에 보완적임\n",
        "6. 샘플링 / 불균형 대응\n",
        "  * undersampling, oversampling, class weights 등 전략 조절\n",
        "  * 특히 시간 순서 유지를 해치지 않도록 샘플링 시 주의 (시간 누수 방지)\n",
        "7. 데이터 누수 방지\n",
        "  * train/test의 시간 순서 유지, future 정보 사용 금지\n",
        "  * transactionDT 기반 분리, 시간 기반 CV 전략 등 중요한 고려사항\n",
        "\n",
        "\n",
        "## 배울 점\n",
        "1. 시간 관련 피처는 단순 파생을 넘어서 해석과 검증이 필요\n",
        "  - TransactionDT를 단순 변환하는 것 이외에도, 거래가 집중되는 시간대/요일 패턴을 시각화해보고, 이 패턴이 fraud 확률과 연관이 있는지 확인하는 게 중요함\n",
        "  - 예: 특정 시간대(심야/새벽) 거래가 사기 확률 높을 가능성\n",
        "\n",
        "2. Lag / Rolling 기반 피처는 시간 누수(leakage)에 특히 취약\n",
        "  * 미래 거래 데이터를 현재 피처로 활용하면 안 됨\n",
        "  * 과거 N 거래 혹은 과거 특정 기간까지만 반영하는 방식이어야 함\n",
        "\n",
        "3. 그룹별 패턴 변화 캡처\n",
        "  * 고객 또는 카드 단위로 시간 흐름에 따라 거래 특성이 바뀔 수 있음. UID 기반의 그룹 집계 + 변화율 변화 추이 피처가 유용\n",
        "  * 예: 최근 7일 대비 30일 패턴 변화율 등\n",
        "\n",
        "4. 불균형 + 시계열 CV 전략 선택 중요\n",
        "  * 랜덤 샘플링보다는, 시간 순서를 고려한 time-based split이나 fold 내 미래 누수 방지 기법을 써야 함\n",
        "  * K-Fold 형태보다는 sliding window 또는 expanding window 방식을 쓰는 게 일반적\n",
        "\n",
        "5. 앙상블/튜닝 vs 단일 복잡 모델의 균형\n",
        "  * 시계열 흐름을 다 잡는 깊은 네트워크보다, 여러 boosting 모델이 조합하는 방식이 보통 더 안정적\n",
        "  * 복잡한 딥러닝 모델을 쓸 경우 과적합 조심\n",
        "\n",
        "6. 성능 해석 & feature importance 분석\n",
        "  * 상위권은 단순히 예측 정확도 뿐 아니라, 어떤 시간대/어떤 카드 특성 그룹에서 오답이 많은지 분석\n",
        "\n",
        "  * feature importance + time-slice별 분석을 같이 해야 함\n",
        "\n",
        "\n",
        "## 구체적인 내용\n",
        "### EDA\n",
        "1. 데이터 구조 확인\n",
        "  - TransactionDT: 거래 발생 시간을 나타내는 변수 (초 단위 누적)\n",
        "  - TransactionAmt: 거래 금액\n",
        "  - card1 ~ card6: 카드 관련 식별자\n",
        "  - addr1, addr2, P_emaildomain: 고객 지역/이메일 정보\n",
        "  - D1~D15: 이전 거래 시점 대비 시간차\n",
        "  - isFraud: 타깃 (1=사기, 0=정상)\n",
        "\n",
        "2. 결과\n",
        "  - Fraud 비율은 전체의 약 3~4% 수준 → 불균형 데이터\n",
        "  - 거래 금액(TransactionAmt) 분포: 소액에 치중, 일부 이상치 존재\n",
        "  - 시간(TransactionDT): 약 6개월 정도 기간, 주기성 확인 가능\n",
        "  - Fraud는 특정 시간대(심야/주말)에서 비중이 상대적으로 높음\n",
        "\n",
        "\n",
        "\n",
        "## 시간 파생 피처\n",
        "1. 거래 시간 기반\n",
        "  - day = TransactionDT // (24*60*60) (일 단위 인덱스)\n",
        "  - weekday = day % 7 (요일)\n",
        "  - hour = (TransactionDT // 3600) % 24 (시간대)\n",
        "\n",
        "2. 고객별 시계열 특성\n",
        "  - Lag / Rolling Features\n",
        "    * 최근 N일간 거래 수 (count_7d, count_30d)\n",
        "    * 최근 N일간 평균 거래 금액 (mean_amt_7d, mean_amt_30d)\n",
        "    * 최근 거래 간 시간 간격(diff_time)\n",
        "\n",
        "  - 통계량 집계\n",
        "    * UID(고객 식별자: card1+addr1+email 조합)별 mean_amt, std_amt, max_amt\n",
        "\n",
        "  - 변화율/트렌드\n",
        "    * 최근 7일 평균 대비 30일 평균 비율\n",
        "    * 거래 금액 추세(선형 회귀 기울기)\n",
        "\n",
        "3. 주기성/행태 피처\n",
        "  - 요일별 거래 패턴\n",
        "  - 휴일/비휴일, 업무 시간/비업무 시간 여부\n",
        "\n",
        "\n",
        "## 모델\n",
        "1. 주력 모델\n",
        "- LightGBM / XGBoost / CatBoost\n",
        "- 대규모 tabular + 불균형 데이터에 최적\n",
        "\n",
        "2. 불균형 대응\n",
        "- scale_pos_weight(LGBM), class_weights(CatBoost)\n",
        "- 언더샘플링/오버샘플링 (단, 시간순서 깨지지 않도록 주의)\n",
        "\n",
        "3. 앙상블\n",
        "- 서로 다른 boosting 모델 + 여러 seed 학습 결과 평균/Rank averaging\n",
        "- 일부 팀은 신경망(RNN/Transformer) 보조적 사용 → boosting보다 성능 낮음\n",
        "\n",
        "\n",
        "## 검증 전략\n",
        "  1. 시간 기반 분할\n",
        "  * Train = 과거 구간 / Validation = 미래 구간 (Expanding Window)\n",
        "  * Random K-Fold 사용 시, 미래 정보 누수(leakage) 발생 위험 큼\n",
        "\n",
        "2. Cross-validation\n",
        "  * 고객 단위로 GroupKFold 적용 (같은 고객이 train/test에 동시에 들어가지 않도록 방지)\n",
        "\n",
        "3. 평가지표\n",
        "  * AUC (리더보드와 일치)\n",
        "  * Precision-Recall Curve도 함께 모니터링 (불균형 문제 대응)"
      ],
      "metadata": {
        "id": "R_owNGcNVlQZ"
      }
    }
  ]
}